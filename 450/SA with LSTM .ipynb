{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comments.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
    "reviews = all_text.split('\\n')\n",
    "\n",
    "all_text = ' '.join(reviews)\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'অনেক ধন্যবাদ প্রথম আলোকে প্রতিভার মূল্যায়ন করায় এর জন্য কালো টাকা সাদা করতেছে সরকার সিনবাদ কি পুরনো পর্ব দেখাবেন না নতুন পর্ব মাস্টার তুমি খুব খারাপ লোক মায়ানমারের সেনাবাহিনী যে আতঙ্ক ছড়িয়ে দিয়েছে যারা এগুলো করতে পারে  তারা মানুষ নামে পশু মুসা ভাই আমাদের দেশের সম্পদ দুদক ঔনার একটা ভাল ছিড়তে পারবে না দেখিয়ে দিয়েছে বাংলাদেশ  জয় বাংলা ধন্যবাদ দিয়ে ছোট করবনা যে সব ছাত্রলীগের জানোয়ারেরা বিভিন্ন জায়গায় সাধারণ ছাত্রছাত্রী দের মেরেছে এদের ভালো করে চিনে রাখুন ভালো লাগলো কবিতা এত টাকা লাগবেনা এর মধ্য থেকে মাত্র এক টাকা মরার সমায় তারে নিতে বলেন দেখা যাবে সত্যের জয় আছে মিথ্যা দিয়ে কোনো কিছু গোপন করা যায় না।।। বন্ধ হোক ওয়েবসাইট এভাবেই আমাদের এগুতে হবে। প্রতিদিন। বিপক্ষ বিদ্রূপের হাসি ভাই আমারে তর ps বানাইয়া ল টাকা বেশি দিতে অইবনাP P আজ  থেকে যারা  বাংলার  মাটিতে রেন্ডিয়া  কে সাপোর্ট করবে  তারা  অরজিন্যাল   গরুর বাচ্চা হি হি হিফোঁকলা দাঁতের হাসি অর্থনৈতিক শোষণ রাজনৈতিক নিপীড়ন সাংস্কৃতিক গোলামী সীমান্ত হত্যাকান্ড ঝুলে থাকা ফেলানীর লাশ পিলখানা হত্যাকান্ড তিস্তার পানি চুক্তি দুই বাংলা এক হয়ে যাক সিকিমের মত অঙ্গরাজ্য হয়ে যাক মাদক চোরাচালানে সীমান্ত উন্মুক্ত ইসলাম মুছে যাক অবৈধ করিডোর এসবে মোর কি এসে যায়তবুও ভারত বন্ধু মোদের ইশ সব শেষ হয়ে গেল যখন ক্রিকেটের উত্থানে চোখে আঙুল দিয়ে রেন্ডিয়া দেখিয়ে দিচ্ছে বাংলাদেশের সর্ব উন্নতিতে তারা কত দয়ালু ক্রিকেট নামক মুলা ধরে যখন টান দিয়েছে সেই টান এসে মোর কলিজায় লেগেছে চোখের পানি নাকের পানি এক করে গোটা বাংলাদেশ আজ মরিমরি অবস্থা অথচ কাঁটাতারে আমার বোন ফেলানীর লাশ ঝুলন্ত দেখে আমার চোখে জল আসেনি নিরীহ বাঙালী কে সীমান্তে হত্যা করতে দেখে আমার হুশ ফেরেনি ফারাক্কা আর টিঁপাইমুখে বাঁধে দেশ মরু হয়ে গেলেও আমার কিচ্ছু যায় আসে না পিলখানা ৫৭ জন সেনা অফিসার খুনেও ঘুম ভাঙ্গেনি ৬ লাখ ৬৭ হাজার কোটি টাকা চুরি হতে দেখেও মনে হয়েছে ইন্ডিয়া মোদের বন্ধু দেশ হে হে হে ১৯৭১ সালের পর থেকে ভারত মাতার বিরুদ্ধে একদল মানুষ ভালো করেই বুঝেছিলো রেন্ডিয়া মোদের কত বড় বন্ধু রাষ্ট্র বেশী \\tবোঝার ফলে সেই দলের সবার গলায় ঝুলছে ফাঁসির রশি ঐ যে র নামক একটি গোয়েন্দা সংস্থা আছে নাওরাই তো সব আজন্ম সালজ্য সাধ তোমায় এভাবে একবার নাচিতে দেখিব সব কিছু মেনে নেওয়া যায় না এই বিষয়টার সু'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_text[:2026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['অনেক',\n",
       " 'ধন্যবাদ',\n",
       " 'প্রথম',\n",
       " 'আলোকে',\n",
       " 'প্রতিভার',\n",
       " 'মূল্যায়ন',\n",
       " 'করায়',\n",
       " 'এর',\n",
       " 'জন্য',\n",
       " 'কালো',\n",
       " 'টাকা',\n",
       " 'সাদা',\n",
       " 'করতেছে',\n",
       " 'সরকার',\n",
       " 'সিনবাদ',\n",
       " 'কি',\n",
       " 'পুরনো',\n",
       " 'পর্ব',\n",
       " 'দেখাবেন',\n",
       " 'না',\n",
       " 'নতুন',\n",
       " 'পর্ব',\n",
       " 'মাস্টার',\n",
       " 'তুমি',\n",
       " 'খুব',\n",
       " 'খারাপ',\n",
       " 'লোক',\n",
       " 'মায়ানমারের',\n",
       " 'সেনাবাহিনী',\n",
       " 'যে',\n",
       " 'আতঙ্ক',\n",
       " 'ছড়িয়ে',\n",
       " 'দিয়েছে',\n",
       " 'যারা',\n",
       " 'এগুলো',\n",
       " 'করতে',\n",
       " 'পারে',\n",
       " 'তারা',\n",
       " 'মানুষ',\n",
       " 'নামে',\n",
       " 'পশু',\n",
       " 'মুসা',\n",
       " 'ভাই',\n",
       " 'আমাদের',\n",
       " 'দেশের',\n",
       " 'সম্পদ',\n",
       " 'দুদক',\n",
       " 'ঔনার',\n",
       " 'একটা',\n",
       " 'ভাল']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "reviews_ints = []\n",
    "for each in reviews:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in each.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.split('\\n')\n",
    "labels = np.array([1 if each == 'positive' else 0 for each in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 0\n",
      "Maximum review length: 447\n"
     ]
    }
   ],
   "source": [
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8578"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "len(non_zero_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 200\n",
    "features = np.zeros((len(reviews_ints), seq_len), dtype=int)\n",
    "for i, row in enumerate(reviews_ints):\n",
    "    features[i, -len(row):] = np.array(row)[:seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ..., 10393,  2113,  1924],\n",
       "       [    0,     0,     0, ...,   938,  1678,    75],\n",
       "       [    0,     0,     0, ...,     1,   193,  2327],\n",
       "       ..., \n",
       "       [    0,     0,     0, ...,    56,   161,   131],\n",
       "       [    0,     0,     0, ...,    25,   325,  6591],\n",
       "       [    0,     0,     0, ...,     2,  2115,  1925]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:10,:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(6862, 200) \n",
      "Validation set: \t(858, 200) \n",
      "Test set: \t\t(858, 200)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "split_idx = int(len(features)*0.8)\n",
    "train_x, val_x = features[:split_idx], features[split_idx:]\n",
    "train_y, val_y = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(val_x)*0.5)\n",
    "val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
    "val_y, test_y = val_y[:test_idx], val_y[test_idx:]\n",
    "\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_size = 256\n",
    "lstm_layers = 1\n",
    "batch_size = 500\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = len(vocab_to_int) + 1 # Adding 1 because we use 0's for padding, dictionary started at 1\n",
    "\n",
    "# Create the graph object\n",
    "graph = tf.Graph()\n",
    "# Add nodes to the graph\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "    labels_ = tf.placeholder(tf.int32, [None, None], name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 \n",
    "\n",
    "with graph.as_default():\n",
    "    embedding = tf.Variable(tf.random_uniform((n_words, embed_size), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Your basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    \n",
    "    # Add dropout to the cell\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with graph.as_default():\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, embed,\n",
    "                                             initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=tf.sigmoid)\n",
    "    cost = tf.losses.mean_squared_error(labels_, predictions)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=100):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 Iteration: 5 Train loss: 0.032\n",
      "Epoch: 0/10 Iteration: 10 Train loss: 0.000\n",
      "Epoch: 1/10 Iteration: 15 Train loss: 0.000\n",
      "Epoch: 1/10 Iteration: 20 Train loss: 0.000\n",
      "Epoch: 1/10 Iteration: 25 Train loss: 0.000\n",
      "Val acc: 1.000\n",
      "Epoch: 2/10 Iteration: 30 Train loss: 0.000\n",
      "Epoch: 2/10 Iteration: 35 Train loss: 0.000\n",
      "Epoch: 3/10 Iteration: 40 Train loss: 0.000\n",
      "Epoch: 3/10 Iteration: 45 Train loss: 0.000\n",
      "Epoch: 3/10 Iteration: 50 Train loss: 0.000\n",
      "Val acc: 1.000\n",
      "Epoch: 4/10 Iteration: 55 Train loss: 0.000\n",
      "Epoch: 4/10 Iteration: 60 Train loss: 0.000\n",
      "Epoch: 4/10 Iteration: 65 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 70 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 75 Train loss: 0.000\n",
      "Val acc: 1.000\n",
      "Epoch: 6/10 Iteration: 80 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 85 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 90 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 95 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 100 Train loss: 0.000\n",
      "Val acc: 1.000\n",
      "Epoch: 8/10 Iteration: 105 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 110 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 115 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 120 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 125 Train loss: 0.000\n",
      "Val acc: 1.000\n",
      "Epoch: 9/10 Iteration: 130 Train loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, None],\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state}\n",
    "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
    "            \n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "\n",
    "            if iteration%25==0:\n",
    "                val_acc = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                for x, y in get_batches(val_x, val_y, batch_size):\n",
    "                    feed = {inputs_: x,\n",
    "                            labels_: y[:, None],\n",
    "                            keep_prob: 1,\n",
    "                            initial_state: val_state}\n",
    "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "            iteration +=1\n",
    "    saver.save(sess, \"checkpoints/sentiment.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/sentiment.ckpt\n",
      "Test accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    for ii, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
    "        feed = {inputs_: x,\n",
    "                labels_: y[:, None],\n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state}\n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
