{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data = pd.read_csv('againdata.csv')\n",
    "sentiment_data.columns =['Class', 'Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>খুব খারাপ লাগলো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>বর্তমান পৃথিবীর সব থেকে বড় বর্বর জাতি মিয়ানমার</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ভালো মানুদের এভাবে মরতে হয়না</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>মন টা খারাপ হয়ে গেলো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>আমাৱ মতে এখন ওদেৱ উপৱ হামলা কৱা হুক</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                            Data\n",
       "0      0                                 খুব খারাপ লাগলো\n",
       "1      0  বর্তমান পৃথিবীর সব থেকে বড় বর্বর জাতি মিয়ানমার\n",
       "2      0                   ভালো মানুদের এভাবে মরতে হয়না\n",
       "3      0                            মন টা খারাপ হয়ে গেলো\n",
       "4      0             আমাৱ মতে এখন ওদেৱ উপৱ হামলা কৱা হুক"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "sentiment_data = shuffle(sentiment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>0</td>\n",
       "      <td>না না এটা ভুয়া খবর</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>0</td>\n",
       "      <td>শুরুতে ঝামেলা হলে শেষ পর্যন্ত তো তা এড়ানো মুশকিল</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>1</td>\n",
       "      <td>শুভকামনা</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5413</th>\n",
       "      <td>1</td>\n",
       "      <td>সত্যিকারের গনমানুষের নেতা এর্দোগান।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718</th>\n",
       "      <td>1</td>\n",
       "      <td>অভিজ্ঞতা ই জ্ঞান এর উৎস! প্রত্যেক মূহুর্ত ই শি...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class                                               Data\n",
       "2520      0                                 না না এটা ভুয়া খবর\n",
       "1842      0  শুরুতে ঝামেলা হলে শেষ পর্যন্ত তো তা এড়ানো মুশকিল\n",
       "7577      1                                           শুভকামনা\n",
       "5413      1                সত্যিকারের গনমানুষের নেতা এর্দোগান।\n",
       "6718      1  অভিজ্ঞতা ই জ্ঞান এর উৎস! প্রত্যেক মূহুর্ত ই শি..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sentiment_data.iloc[:, 0].values\n",
    "reviews = sentiment_data.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_processed = []\n",
    "for review in reviews:\n",
    "    review_cool_one = ''.join([char for char in review if char not in punctuation])\n",
    "    reviews_processed.append(review_cool_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_reviews = []\n",
    "\n",
    "all_words = []\n",
    "for review in reviews_processed:\n",
    "    word_reviews.append(review.lower().split())\n",
    "    for word in review.split():\n",
    "        all_words.append(word.lower())\n",
    "\n",
    "\n",
    "    \n",
    "counter = Counter(all_words)\n",
    "vocab = sorted(counter, key=counter.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int = {word: i for i, word in enumerate(vocab, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_to_ints = []\n",
    "for review in word_reviews:\n",
    "    reviews_to_ints.append([vocab_to_int[word] for word in review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length 0\n",
      "Max review length 447\n"
     ]
    }
   ],
   "source": [
    "reviews_lens = Counter([len(x) for x in reviews_to_ints])\n",
    "print('Zero-length {}'.format(reviews_lens[0]))\n",
    "print(\"Max review length {}\".format(max(reviews_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_len = 250\n",
    "\n",
    "features = np.zeros((len(reviews_to_ints), seq_len), dtype=int)\n",
    "for i, review in enumerate(reviews_to_ints):\n",
    "    features[i, -len(review):] = np.array(review)[:seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trian shape (6400, 250)\n"
     ]
    }
   ],
   "source": [
    "X_train = features[:6400]\n",
    "y_train = labels[:6400]\n",
    "\n",
    "X_test = features[6400:]\n",
    "y_test = labels[6400:]\n",
    "\n",
    "\n",
    "\n",
    "print('X_trian shape {}'.format(X_train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 512 # how many nodes LSTM cells will have\n",
    "number_of_layers = 1 # how many RNN layers the network will use\n",
    "batch_size = 100 # how many reviews we feed at onces\n",
    "learning_rate = 0.001 # learning rate\n",
    "number_of_words = len(vocab_to_int) + 1 #how many unique words do we have in vocab (+1  is used for 0 - padding)\n",
    "dropout_rate = 0.8 \n",
    "embed_size = 300 #how long our word embedings will be\n",
    "epochs = 6 # how many epochs do we use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #Clean the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "targets = tf.placeholder(tf.int32, [None, None], name='targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedings = tf.Variable(tf.random_uniform((number_of_words, embed_size), -1, 1))\n",
    "embed = tf.nn.embedding_lookup(word_embedings, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = tf.contrib.rnn.BasicLSTMCell(hidden_layer_size)\n",
    "hidden_layer = tf.contrib.rnn.DropoutWrapper(hidden_layer, dropout_rate)\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell([hidden_layer]*number_of_layers)\n",
    "init_state = cell.zero_state(batch_size, tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(cell, embed, initial_state=init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.layers.dense(outputs[:, -1], 1, activation=tf.sigmoid)\n",
    "cost = tf.losses.mean_squared_error(targets, prediction)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "currect_pred = tf.equal(tf.cast(tf.round(prediction), tf.int32), targets)\n",
    "accuracy = tf.reduce_mean(tf.cast(currect_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/6  | Current loss: 0.2080979198217392  | Training accuracy: 66.9375\n",
      "Epoch: 1/6  | Current loss: 0.1417398452758789  | Training accuracy: 79.9844\n",
      "Epoch: 2/6  | Current loss: 0.10530947148799896  | Training accuracy: 86.5781\n",
      "Epoch: 3/6  | Current loss: 0.07047310471534729  | Training accuracy: 91.0937\n",
      "Epoch: 4/6  | Current loss: 0.049688003957271576  | Training accuracy: 94.0156\n",
      "Epoch: 5/6  | Current loss: 0.03608681261539459  | Training accuracy: 95.7656\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    training_accurcy = []\n",
    "    ii = 0\n",
    "    epoch_loss = []\n",
    "    while ii + batch_size <= len(X_train):\n",
    "        X_batch = X_train[ii:ii+batch_size]\n",
    "        y_batch = y_train[ii:ii+batch_size].reshape(-1, 1)\n",
    "        \n",
    "        a, o, _ = session.run([accuracy, cost, optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
    "\n",
    "        training_accurcy.append(a)\n",
    "        epoch_loss.append(o)\n",
    "        ii += batch_size\n",
    "    print('Epoch: {}/{}'.format(i, epochs), ' | Current loss: {}'.format(np.mean(epoch_loss)),\n",
    "          ' | Training accuracy: {:.4f}'.format(np.mean(training_accurcy)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = []\n",
    "\n",
    "ii = 0\n",
    "while ii + batch_size <= len(X_test):\n",
    "    X_batch = X_test[ii:ii+batch_size]\n",
    "    y_batch = y_test[ii:ii+batch_size].reshape(-1, 1)\n",
    "\n",
    "    a = session.run([accuracy], feed_dict={inputs:X_batch, targets:y_batch})\n",
    "    \n",
    "    test_accuracy.append(a)\n",
    "    ii += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 78.9524%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy is {:.4f}%\".format(np.mean(test_accuracy)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
